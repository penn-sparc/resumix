import json
import numpy as np
import faiss
from resumix.shared.utils.sentence_transformer_utils import SentenceTransformerUtils
from pathlib import Path
from resumix.config.config import Config

CONFIG = Config().config


def build_faiss_index(
    data_save_path: str = CONFIG.RAG.DATA_PATH,
    index_save_path: str = CONFIG.RAG.INDEX_PATH,
):
    # 1. åŠ è½½è¯­æ–™

    # ğŸŒŸ æ‰“å°å‡ºè·¯å¾„æ˜¯æ€ä¹ˆè§£æçš„
    print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
    print(f"ğŸ“„ å°è¯•ä¿å­˜ data.json åˆ°: {Path(data_save_path).resolve()}")
    print(f"ğŸ“„ å°è¯•ä¿å­˜ index.json åˆ°: {Path(index_save_path).resolve()}")

    data = [
        {
            "text": "Developed a distributed microservices backend using Golang and gRPC, achieving 99.9% uptime and supporting over 10 million daily requests."
        },
        {
            "text": "Deployed and managed Kubernetes clusters for staging and production environments, ensuring seamless CI/CD integration and blue-green releases."
        },
        {
            "text": "Built RESTful and gRPC APIs for internal services, including authentication, task scheduling, and data ingestion modules."
        },
        {
            "text": "Implemented monitoring and logging solutions using Prometheus and Grafana to improve system observability and reliability."
        },
        {
            "text": "Collaborated with product managers and frontend engineers to deliver scalable features under Agile development practices."
        },
        {
            "text": "Designed a message queue architecture using Kafka and Redis Stream to decouple services and improve throughput under high concurrency."
        },
        {
            "text": "Proficient in Golang, Docker, Kubernetes, MySQL, Redis, and Git; experienced in cloud-native backend system development."
        },
        {
            "text": "Job Requirement: Strong experience with Go or Java backend development; familiarity with container orchestration platforms like Kubernetes."
        },
        {
            "text": "Job Requirement: Ability to design and implement high-concurrency systems, optimize service latency, and handle distributed transactions."
        },
        {
            "text": "Job Requirement: Knowledge of microservices, API gateway, service mesh (e.g., Istio), and gRPC-based service-to-service communication."
        },
    ]

    texts = [entry["text"] for entry in data]

    # 2. åµŒå…¥ç¼–ç 
    model = SentenceTransformerUtils.get_instance()
    embeddings = model.encode(texts, normalize_embeddings=True).astype(np.float32)

    # 3. æ„å»ºå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨ç‚¹ç§¯ä½œä¸ºç›¸ä¼¼åº¦ï¼‰
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)

    # 4. ä¿å­˜ç´¢å¼•
    faiss.write_index(index, index_save_path)
    print(f"âœ… FAISS index saved to {index_save_path}")

    # âœ… åŒæ—¶ä¿å­˜æ–‡æœ¬æ•°æ®
    with open(data_save_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"âœ… FAISS index saved to {index_save_path}")
    print(f"âœ… Text data saved to {data_save_path}")


# ç”¨æ³•ç¤ºä¾‹
if __name__ == "__main__":
    import os

    print("å½“å‰å·¥ä½œç›®å½•æ˜¯:", os.getcwd())
    build_faiss_index()
